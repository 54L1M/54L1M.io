---
title: "Estimating Photometric Redshifts of Galaxies and QSOs with Machine Learning"
date: 2024-10-17
author: Salim
tags: ["Machine-Learning", "Astrophysics", "Redshifts", "Random-Forest", "Decision-Tree", "python"]
categories: Projects
summary: "A comprehensive look at leveraging machine learning techniques to estimate photometric redshifts using Sloan Digital Sky Survey (SDSS) data. This post explores methodologies, results, and implications for modern cosmology."
---

## Introduction

In the vast expanse of the universe, understanding the structure and evolution of celestial objects requires accurate distance measurements. Redshift, a fundamental parameter in astrophysics, serves as a proxy for determining these distances. However, acquiring spectroscopic measurements, the traditional method for calculating redshift, is a resource-intensive process. Large-scale surveys, such as the Sloan Digital Sky Survey (SDSS), have created the need for faster, scalable methods to estimate redshifts across millions of objects. 

In our published research, we explored how machine learning (ML) algorithms, specifically regression models like decision trees and random forests, can estimate photometric redshifts using features derived from SDSS photometric data. This approach bridges the gap between efficiency and accuracy, enabling cosmologists to analyze vast datasets while minimizing the need for spectroscopic observations.

This blog delves into the details of our study, the methodologies employed, the results achieved, and the broader implications for astrophysics in the era of big data.

---

## Background: Why Photometric Redshift Estimation?

### Redshift: A Key Metric in Cosmology

Redshift is the phenomenon where light from distant objects shifts to longer wavelengths due to the expansion of the universe. It is an essential tool for calculating the distances of galaxies, quasars (QSOs), and other astronomical sources. Determining redshift helps cosmologists map the universe’s structure, study galaxy clustering, and explore dark energy.

### The Challenge of Spectroscopy

While spectroscopic redshift measurements are precise, they require high-resolution spectra obtained through time-consuming and costly observations. For instance, SDSS has cataloged over 2.6 million spectroscopic redshifts, but this represents only a fraction of the universe's observable objects. The majority of SDSS's 100 million galaxy observations rely on photometry, a faster but less precise method based on broadband filters.

### The Role of Machine Learning

Machine learning offers a powerful alternative to traditional methods. By analyzing patterns in photometric data, ML algorithms can estimate redshifts with high accuracy, making it possible to handle the massive datasets generated by modern surveys. This research demonstrates how decision tree and random forest regression algorithms can be applied effectively to this problem.

---

## Methodology: How We Approached the Problem

### Data Source: Sloan Digital Sky Survey (SDSS)

The study utilized data from SDSS Data Release 16 (DR16), which includes both photometric and spectroscopic observations. The key features for our analysis were **color indices**, derived from flux magnitudes measured in five optical bands: u, g, r, i, and z. These indices approximate the spectral information of objects, making them ideal for ML-based redshift estimation.

### Machine Learning Algorithms

We employed two ML regression algorithms:

1. **Decision Trees**:
   - Decision trees are hierarchical models that split data based on specific criteria at each node, leading to a prediction at the leaf nodes.
   - The key hyperparameter is the tree depth, which we optimized to avoid overfitting.

2. **Random Forests**:
   - Random forests are ensembles of decision trees, where each tree is trained on a random subset of data and features.
   - By aggregating predictions from multiple trees, random forests reduce variance and improve accuracy.

### Dataset Preparation

- **Training and Testing**: The dataset was split into training (80%) and testing (20%) subsets.
- **Feature Engineering**: Color indices served as input features, and spectroscopic redshifts were used as the ground truth for training and evaluation.
- **Data Filtering**: To enhance performance, we focused on two subsets:
  1. The full dataset with all redshifts.
  2. A filtered dataset with redshifts ≤ 2, which removed outliers and reduced complexity.

### Performance Metrics

We evaluated the models using:
- **Accuracy**: The percentage of correct predictions within a given tolerance.
- **Root Mean Square Error (RMSE)**: The standard deviation of prediction errors.
- **Normalized Standard Deviation (∆Z_norm)**: A metric for quantifying relative prediction errors.

---

## Results: Key Findings

### Decision Tree Performance

- **Full Dataset**:
  - Accuracy: 70.17%
  - RMSE: 0.28
  - ∆Z_norm: 0.0135
- **Filtered Dataset (z ≤ 2)**:
  - Accuracy: 85.26%
  - RMSE: 0.16
  - ∆Z_norm: 0.005

While decision trees performed well, they exhibited limitations such as overfitting to noise in the full dataset. However, filtering redshifts improved their accuracy significantly by reducing the variability in the target values.

### Random Forest Performance

- **Full Dataset**:
  - Accuracy: 81.02%
  - RMSE: 0.23
  - ∆Z_norm: 0.013
- **Filtered Dataset (z ≤ 2)**:
  - Accuracy: 91.00%
  - RMSE: 0.12
  - ∆Z_norm: 0.005

Random forests outperformed decision trees across all metrics. The ensemble approach mitigated overfitting and produced more reliable estimates, especially for the filtered dataset.

### Visual Analysis

The scatter plots of predicted vs. true redshifts revealed tighter clustering along the ideal 1:1 line for the random forest model. Contour maps of redshifts based on color indices further demonstrated the strong correlation between input features and redshift estimates.

---

## Discussion: What the Results Mean

### Why Random Forests Excelled

Random forests leverage ensemble learning to overcome the inherent biases and variances of individual decision trees. By combining predictions from multiple trees, they provided a more robust estimation of redshifts, even for noisy or incomplete data.

### The Impact of Data Filtering

Filtering the dataset to redshifts ≤ 2 had a profound impact on performance. This subset removed outliers and ensured a more uniform distribution of target values, allowing the models to learn patterns more effectively.

### Implications for Future Research

The success of these ML techniques underscores their potential for large-scale astronomical surveys. Future work could explore:
- Incorporating additional features, such as morphological data.
- Extending the methodology to other surveys beyond SDSS.
- Leveraging deep learning architectures for further accuracy improvements.

---

## Broader Implications for Astrophysics

As astronomical surveys grow in scale, the era of big data is transforming astrophysics. Photometric redshift estimation is a prime example of how ML can tackle challenges associated with vast datasets. By reducing reliance on spectroscopy, ML-based approaches free up resources for more targeted studies and enable deeper insights into cosmic phenomena.

This research also highlights the interdisciplinary nature of modern science, where physics, astronomy, and data science converge to solve complex problems. The tools and techniques developed here have applications beyond redshift estimation, from galaxy classification to transient event detection.

---

## Conclusion

Our study demonstrates the power of machine learning in estimating photometric redshifts, achieving high accuracy with random forest regression. By using color indices from SDSS data, we bridged the gap between efficiency and precision, paving the way for scalable solutions in astrophysics.

The results underscore the importance of thoughtful feature engineering, algorithm selection, and data preparation. As new surveys generate even larger datasets, ML will undoubtedly play a central role in unlocking the secrets of the universe.

For more details, check out the full paper [here](https://www.worldscientific.com/doi/pdf/10.1142/9789811269776_0027), where we dive deeper into the methodologies and statistical analyses.